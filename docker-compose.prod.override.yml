services:
  nginx:
    # Security hardening overrides
    read_only: true
    user: "101:101" # non-root (adjust if base image UID/GID differ)
    cap_drop: ["ALL"]
    cap_add: ["NET_BIND_SERVICE"]
    # security_opt removed here to avoid duplicate merged entries; base prod file already sets
    #   - no-new-privileges:true
    # Add seccomp once profile is available:
    # security_opt:
    #   - no-new-privileges:true
    #   - seccomp:./security/seccomp-tight.json
    tmpfs:
      # Specify uid/gid/mode so non-root (101) can create temp cache dirs without chmod logic
      - /var/cache/nginx:rw,noexec,nosuid,nodev,size=64m,uid=101,gid=101,mode=0755
      - /var/run:rw,noexec,nosuid,nodev,size=16m,uid=101,gid=101,mode=0755
    ulimits:
      nofile: 65536
    healthcheck:
      # Hardened curl healthcheck: fast connect, bounded total retry window
      test: ["CMD", "sh", "-c", "curl --connect-timeout 2 --retry 5 --retry-delay 2 --retry-max-time 15 -fsS -o /dev/null http://127.0.0.1/_up || exit 1"]
      interval: 10s
      timeout: 4s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "0.50"
          memory: 256M
        reservations:
          memory: 128M
    volumes:
      # Persist SSL certs (Letâ€™s Encrypt); kept read-only inside container via :ro in base file
      - letsencrypt:/etc/letsencrypt

  cloudflared:
    image: cloudflare/cloudflared:latest
    # Credentials-file mode (authoritative). Place <UUID>.json + config.yml under ./cloudflared
    # Acquire credentials:
    #   cloudflared tunnel login
    #   cloudflared tunnel create ledgermind-prod   (produces <UUID>.json)
    # Create ./cloudflared/config.yml with:
    #   tunnel: <UUID>
    #   credentials-file: /etc/cloudflared/<UUID>.json
    #   ingress:
    #     - hostname: app.ledger-mind.org
    #       service: http://nginx:80
    #     - service: http_status:404
    command: [
      "tunnel",
      "--config","/etc/cloudflared/config.yml",
      "--no-autoupdate",
      "--loglevel","info",
      "--protocol","auto",
      "--metrics","0.0.0.0:2000",
      "run"
    ]
    environment:
      # Ensure token mode is fully disabled even if base compose supplies it
      TUNNEL_TOKEN: ""
    volumes:
      - ./cloudflared:/etc/cloudflared:ro
    read_only: true
    cap_drop: ["ALL"]
    cap_add: ["NET_BIND_SERVICE"]
    security_opt:
      - no-new-privileges:true
      # - seccomp:./security/seccomp-tight.json
    restart: unless-stopped
    depends_on:
      nginx:
        condition: service_healthy
    healthcheck:
      # Simple metrics probe; exits non-zero if metric missing
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:2000/metrics | grep -q cloudflared_tunnel_ha_connections"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s

  backend:
    # Disable secret mount locally on Windows; use env fallback instead
    secrets: []
    env_file:
      - ./secrets/backend.env
    read_only: true
    user: "10001:10001"
    cap_drop: ["ALL"]
    security_opt:
      - no-new-privileges:true
      # - seccomp:./security/seccomp-tight.json
    tmpfs:
      - /tmp:rw,noexec,nosuid,nodev,size=64m
    volumes:
      # Mount the actual service account JSON file (host path is a directory containing the file)
      - ./secrets/gcp-sa.json/ledgermind-backend-sa.json:/secrets/gcp-sa.json:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys;hdr={'Host':'backend'};\nfor u in ('http://127.0.0.1:8000/live','http://127.0.0.1:8000/healthz'):\n  try:\n    req=urllib.request.Request(u,headers=hdr);\n    with urllib.request.urlopen(req,timeout=2) as r:\n      if r.getcode()==200: sys.exit(0)\n  except Exception: pass\nsys.exit(1)"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 60s
    depends_on: []
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          memory: 256M

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_MODELS=/root/.ollama
    volumes:
      - ollama-data:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "/bin/ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 30
      start_period: 45s

  ollama-seed:
    image: ollama/ollama:latest
    profiles: ["seed"]
    volumes:
      - ollama-data:/root/.ollama
    entrypoint: ["/bin/sh","-lc"]
    command: |
      set -e
      ollama pull llama3.1:8b    || true
      ollama pull phi3:3.8b      || true
      echo "Seeded models."
    restart: "no"

  debugbox:
    image: alpine:3.20
    command: ["sh", "-lc", "sleep infinity"]
    depends_on:
      - nginx
    networks:
      - default

volumes:
  letsencrypt:
  ollama-data:

# Disable secrets root in local override to avoid Docker Desktop bind errors on Windows
secrets: {}
