services:
  nginx:
    volumes:
      # Ensure SPA build is mounted (already present in base; re-declared here is fine)
      - ./apps/web/dist:/usr/share/nginx/html:ro
      # Use existing repo path for nginx conf
      - ./ops/nginx/conf.d:/etc/nginx/conf.d:ro

      # Persist SSL certs (Let’s Encrypt) — webroot not needed for DNS-01
      - letsencrypt:/etc/letsencrypt

  cloudflared:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    depends_on:
      - nginx
    command: tunnel run
    environment:
      TUNNEL_TOKEN: ${CLOUDFLARE_TUNNEL_TOKEN}
    healthcheck:
      test: ['CMD', 'cloudflared', 'update', 'check']
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    environment:
      OPENAI_BASE_URL: "http://ollama:11434/v1"
      OPENAI_API_KEY: "ollama"
      MODEL: "gpt-oss:20b"
      DEV_ALLOW_NO_LLM: "0"
      MASTER_KEK_B64: ${MASTER_KEK_B64}
      ENCRYPTION_MASTER_KEY_BASE64: ${ENCRYPTION_MASTER_KEY_BASE64:-${MASTER_KEK_B64}}
      CRYPTO_MODE: "kms"
      KMS_PROVIDER: "gcp"
      GCP_KMS_KEY: "projects/ledgermind-03445-3l/locations/us-east1/keyRings/ledgermind/cryptoKeys/kek"
      GOOGLE_APPLICATION_CREDENTIALS: "/gcp/ledgermind-backend-sa.json"
      GRPC_VERBOSITY: "ERROR"
      GRPC_TRACE: ""
    volumes:
      - ./secrets/gcp-sa.json:/gcp:ro

  ollama:
    environment:
      - OLLAMA_MODELS=/root/.ollama
    volumes:
      - 'D:\\ollama:/root/.ollama'

volumes:
  letsencrypt:
