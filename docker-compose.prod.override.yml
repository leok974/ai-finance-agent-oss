services:
  nginx:
    volumes:
      # Ensure SPA build is mounted (already present in base; re-declared here is fine)
      - ./apps/web/dist:/usr/share/nginx/html:ro
      # Use existing repo path for nginx conf
      - ./ops/nginx/conf.d:/etc/nginx/conf.d:ro

      # Persist SSL certs (Let’s Encrypt) — webroot not needed for DNS-01
      - letsencrypt:/etc/letsencrypt

  cloudflared:
    image: cloudflare/cloudflared:latest
    command: ["tunnel","run"]
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    restart: unless-stopped
    depends_on:
      - nginx
    healthcheck:
      test: ['CMD', 'cloudflared', 'update', 'check']
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    environment:
      OPENAI_BASE_URL: "http://ollama:11434/v1"
      OPENAI_API_KEY: "ollama"
      MODEL: "gpt-oss:20b"
      DEV_ALLOW_NO_LLM: "0"
      MASTER_KEK_B64: ${MASTER_KEK_B64}
      ENCRYPTION_MASTER_KEY_BASE64: ${ENCRYPTION_MASTER_KEY_BASE64:-${MASTER_KEK_B64}}
      ENCRYPTION_ENABLED: "1"
      CRYPTO_STRICT_STARTUP: "1"
      KMS_PROVIDER: "gcp"
      GCP_KMS_KEY: "projects/ledgermind-03445-3l/locations/us-east1/keyRings/ledgermind/cryptoKeys/kek"
      GCP_KMS_AAD: "app=ledgermind,env=prod"
      GOOGLE_APPLICATION_CREDENTIALS: "/secrets/gcp-sa.json"
      GRPC_VERBOSITY: "ERROR"
      GRPC_TRACE: ""
    volumes:
      # Mount the specific SA JSON file at the expected path (GOOGLE_APPLICATION_CREDENTIALS must be a file)
      - ./secrets/gcp-sa.json/ledgermind-backend-sa.json:/secrets/gcp-sa.json:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://127.0.0.1:8000/ready').getcode()==200 else sys.exit(1)"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 30s

  ollama:
    environment:
      - OLLAMA_MODELS=/root/.ollama
    volumes:
      - 'D:\\ollama:/root/.ollama'

volumes:
  letsencrypt:
