services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: finance
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U myuser -d finance || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  backend:
    build:
      context: ./apps/backend
    environment:
      APP_ENV: "prod"
      ENCRYPTION_ENABLED: ${ENCRYPTION_ENABLED:-1}
      GCP_KMS_KEY: "projects/ledgermind-03445-3l/locations/us-east1/keyRings/ledgermind/cryptoKeys/kek"
      GCP_KMS_AAD: ${GCP_KMS_AAD}
      GOOGLE_APPLICATION_CREDENTIALS: /secrets/gcp-sa.json
      DATABASE_URL: "postgresql+psycopg://myuser:${POSTGRES_PASSWORD}@postgres:5432/finance"
      CORS_ALLOW_ORIGINS: "https://ledger-mind.org,https://www.ledger-mind.org"
      FRONTEND_ORIGIN: "https://ledger-mind.org"
      COOKIE_SAMESITE: strict
      TRUSTED_PROXY_CIDRS: "172.21.0.0/16"
      # LLM provider configuration
      DEFAULT_LLM_PROVIDER: "openai"
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_BASE_URL: "https://api.openai.com/v1"
      # Comma-separated allowlist for UI model selection (adjust as needed)
      AGENT_ALLOWED_MODELS: "gpt-4o-mini,gpt-4o,gpt-4.1,gpt-4.1-mini,o4-mini,gpt-oss:20b"
      AGENT_PROVIDER: "openai"
      AGENT_DEFAULT_MODEL: "gpt-4o-mini"
      # Explicit default LLM model for backend settings (Settings.DEFAULT_LLM_MODEL)
      DEFAULT_LLM_MODEL: "gpt-4o-mini"
      # Optional direct service base for Ollama (code currently hits 127.0.0.1:11434)
      OLLAMA_BASE_URL: "http://ollama:11434"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - "C:/secrets/ledgermind-backend-sa.json:/secrets/gcp-sa.json:ro"
      - ./apps/backend:/app:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://127.0.0.1:8000/ready').getcode()==200 else sys.exit(1)"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  nginx:
    image: nginx:1.27-alpine
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./ops/nginx/conf.d:/etc/nginx/conf.d:ro
      - certbot_www:/var/www/certbot
      - letsencrypt:/etc/letsencrypt:ro
      - ./apps/web/dist:/usr/share/nginx/html:ro
    ports:
      - "127.0.0.1:80:80"
      - "127.0.0.1:443:443"
    restart: unless-stopped

  certbot:
    image: certbot/certbot:latest
    volumes:
      - certbot_www:/var/www/certbot
      - letsencrypt:/etc/letsencrypt
    entrypoint: ["sh", "-c", "pip install --no-cache-dir certbot-dns-cloudflare && while :; do certbot renew --dns-cloudflare --dns-cloudflare-credentials /etc/letsencrypt/cloudflare.ini --dns-cloudflare-propagation-seconds 120 --quiet || true; sleep 12h; done"]
    restart: unless-stopped

  nginx-reloader:
    image: docker:cli
    depends_on:
      - nginx
    environment:
      NGINX_CONTAINER: "${NGINX_CONTAINER:-ai-finance-agent-oss-clean-nginx-1}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      sh -c 'while :; do sleep 12h; docker exec "$NGINX_CONTAINER" nginx -s reload || true; done'
    restart: unless-stopped

  # Local models runtime (pull & serve models via Ollama API)
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama
    # Enable NVIDIA GPU acceleration (requires Docker Desktop GPU support enabled)
    gpus: all
    environment:
      - OLLAMA_KEEP_ALIVE=5m
    # Uncomment to expose to host for local experiments
    # ports:
    #   - "127.0.0.1:11434:11434"

  # Sidecar to present 127.0.0.1:11434 inside backend netns, forwarding to ollama service

volumes:
  pgdata:
  certbot_www:
  letsencrypt:
  ollama:

